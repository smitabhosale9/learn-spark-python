{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections #for frequeny counting\n",
    "import findspark\n",
    "findspark.init(\"./spark2/\")\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import DataFrameNaFunctions\n",
    "from pyspark.sql.functions import lit #create columns of *literal* value\n",
    "from pyspark.sql.functions import col #Returns columns given on column name\n",
    "from pyspark.ml.feature import StringIndexer #label encoding\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"helloworld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings #for filtering warnings\n",
    "\n",
    "#constants\n",
    "%matplotlib inline\n",
    "sns.set_style(\"dark\")\n",
    "#to ignore warnings in output\n",
    "warnings.filterwarnings('ignore')\n",
    "#global information settings\n",
    "sigLev = 2 #three significant digits\n",
    "percentMul = 100 #for percentage multiplication\n",
    "figWidth = figHeight = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import random\n",
    "import shelve\n",
    "from sklearn import linear_model\n",
    "#from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF = spark.read.csv(\"data/train.csv\", header=\"true\")\n",
    "testDF = spark.read.csv(\"data/test.csv\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add Survived column to test, and dataset name as a column\n",
    "trainDF = trainDF.withColumn('Mark', lit('train'))\n",
    "testDF = (testDF.withColumn('loss',lit(0))\n",
    "                .withColumn('Mark', lit('test')))\n",
    "testDF = testDF[trainDF.columns]\n",
    "\n",
    "## Append Test data to Train data\n",
    "df = trainDF.unionAll(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define function\n",
    "def to_anytype(df, colnames, typename):\n",
    "    for colname in colnames:\n",
    "        df = df.withColumn(\"tmp\", df[colname].cast(typename)) \\\n",
    "        .drop(colname) \\\n",
    "        .withColumnRenamed(\"tmp\", colname)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numVars = ['id','cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10','cont11',\n",
    "             'cont12','cont13','cont14','loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catVars = ['cat1','cat9','cat10','cat11','cat12',\n",
    "              'cat13','cat14','cat15','cat16','cat17','cat18','cat19','cat20','cat21','cat22','cat23',\n",
    "              'cat24','cat25','cat26','cat27','cat28','cat29','cat30','cat31','cat32','cat33','cat34',\n",
    "              'cat35','cat36','cat37','cat38','cat39','cat40','cat41','cat42','cat43','cat44','cat45',\n",
    "              'cat46','cat47','cat48','cat49','cat50','cat51','cat52','cat53','cat54','cat55','cat56',\n",
    "              'cat57','cat58','cat59','cat60','cat61','cat62','cat63','cat64','cat65','cat66','cat67',\n",
    "              'cat68','cat69','cat70','cat71','cat72','cat73','cat74','cat75','cat76','cat77','cat78',\n",
    "              'cat79','cat80','cat81','cat82','cat83','cat84','cat85','cat86','cat87','cat88'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = to_anytype(df, numVars, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make use of pipeline to index all categorical variables\n",
    "def indexer(df, col):\n",
    "    si = StringIndexer(inputCol = col, outputCol = col+'_indexed').fit(df)\n",
    "    return si\n",
    " \n",
    "indexers = [indexer(df, col) for col in catVars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = indexers)\n",
    "df_indexed = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|cat44|cat44_indexed|\n",
      "+-----+-------------+\n",
      "|    A|          0.0|\n",
      "|    A|          0.0|\n",
      "|    A|          0.0|\n",
      "+-----+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.select('cat44','cat44_indexed').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catVarsIndexed = [i + '_indexed' for i in catVars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresCol = numVars + catVarsIndexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cont1',\n",
       " 'cont2',\n",
       " 'cont3',\n",
       " 'cont4',\n",
       " 'cont5',\n",
       " 'cont6',\n",
       " 'cont7',\n",
       " 'cont8',\n",
       " 'cont9',\n",
       " 'cont10',\n",
       " 'cont11',\n",
       " 'cont12',\n",
       " 'cont13',\n",
       " 'cont14',\n",
       " 'cat1_indexed',\n",
       " 'cat9_indexed',\n",
       " 'cat10_indexed',\n",
       " 'cat11_indexed',\n",
       " 'cat12_indexed',\n",
       " 'cat13_indexed',\n",
       " 'cat14_indexed',\n",
       " 'cat15_indexed',\n",
       " 'cat16_indexed',\n",
       " 'cat17_indexed',\n",
       " 'cat18_indexed',\n",
       " 'cat19_indexed',\n",
       " 'cat20_indexed',\n",
       " 'cat21_indexed',\n",
       " 'cat22_indexed',\n",
       " 'cat23_indexed',\n",
       " 'cat24_indexed',\n",
       " 'cat25_indexed',\n",
       " 'cat26_indexed',\n",
       " 'cat27_indexed',\n",
       " 'cat28_indexed',\n",
       " 'cat29_indexed',\n",
       " 'cat30_indexed',\n",
       " 'cat31_indexed',\n",
       " 'cat32_indexed',\n",
       " 'cat33_indexed',\n",
       " 'cat34_indexed',\n",
       " 'cat35_indexed',\n",
       " 'cat36_indexed',\n",
       " 'cat37_indexed',\n",
       " 'cat38_indexed',\n",
       " 'cat39_indexed',\n",
       " 'cat40_indexed',\n",
       " 'cat41_indexed',\n",
       " 'cat42_indexed',\n",
       " 'cat43_indexed',\n",
       " 'cat44_indexed',\n",
       " 'cat45_indexed',\n",
       " 'cat46_indexed',\n",
       " 'cat47_indexed',\n",
       " 'cat48_indexed',\n",
       " 'cat49_indexed',\n",
       " 'cat50_indexed',\n",
       " 'cat51_indexed',\n",
       " 'cat52_indexed',\n",
       " 'cat53_indexed',\n",
       " 'cat54_indexed',\n",
       " 'cat55_indexed',\n",
       " 'cat56_indexed',\n",
       " 'cat57_indexed',\n",
       " 'cat58_indexed',\n",
       " 'cat59_indexed',\n",
       " 'cat60_indexed',\n",
       " 'cat61_indexed',\n",
       " 'cat62_indexed',\n",
       " 'cat63_indexed',\n",
       " 'cat64_indexed',\n",
       " 'cat65_indexed',\n",
       " 'cat66_indexed',\n",
       " 'cat67_indexed',\n",
       " 'cat68_indexed',\n",
       " 'cat69_indexed',\n",
       " 'cat70_indexed',\n",
       " 'cat71_indexed',\n",
       " 'cat72_indexed',\n",
       " 'cat73_indexed',\n",
       " 'cat74_indexed',\n",
       " 'cat75_indexed',\n",
       " 'cat76_indexed',\n",
       " 'cat77_indexed',\n",
       " 'cat78_indexed',\n",
       " 'cat79_indexed',\n",
       " 'cat80_indexed',\n",
       " 'cat81_indexed',\n",
       " 'cat82_indexed',\n",
       " 'cat83_indexed',\n",
       " 'cat84_indexed',\n",
       " 'cat85_indexed',\n",
       " 'cat86_indexed',\n",
       " 'cat87_indexed',\n",
       " 'cat88_indexed']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresCol.remove('id')\n",
    "featuresCol.remove('loss')\n",
    "#featuresCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mark', 'loss']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelCol = ['Mark','loss']\n",
    "labelCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row(mark, label, features)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = Row('mark','label','features') \n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Mark: string, loss: float, cont1: float, cont2: float, cont3: float, cont4: float, cont5: float, cont6: float, cont7: float, cont8: float, cont9: float, cont10: float, cont11: float, cont12: float, cont13: float, cont14: float, cat1_indexed: double, cat9_indexed: double, cat10_indexed: double, cat11_indexed: double, cat12_indexed: double, cat13_indexed: double, cat14_indexed: double, cat15_indexed: double, cat16_indexed: double, cat17_indexed: double, cat18_indexed: double, cat19_indexed: double, cat20_indexed: double, cat21_indexed: double, cat22_indexed: double, cat23_indexed: double, cat24_indexed: double, cat25_indexed: double, cat26_indexed: double, cat27_indexed: double, cat28_indexed: double, cat29_indexed: double, cat30_indexed: double, cat31_indexed: double, cat32_indexed: double, cat33_indexed: double, cat34_indexed: double, cat35_indexed: double, cat36_indexed: double, cat37_indexed: double, cat38_indexed: double, cat39_indexed: double, cat40_indexed: double, cat41_indexed: double, cat42_indexed: double, cat43_indexed: double, cat44_indexed: double, cat45_indexed: double, cat46_indexed: double, cat47_indexed: double, cat48_indexed: double, cat49_indexed: double, cat50_indexed: double, cat51_indexed: double, cat52_indexed: double, cat53_indexed: double, cat54_indexed: double, cat55_indexed: double, cat56_indexed: double, cat57_indexed: double, cat58_indexed: double, cat59_indexed: double, cat60_indexed: double, cat61_indexed: double, cat62_indexed: double, cat63_indexed: double, cat64_indexed: double, cat65_indexed: double, cat66_indexed: double, cat67_indexed: double, cat68_indexed: double, cat69_indexed: double, cat70_indexed: double, cat71_indexed: double, cat72_indexed: double, cat73_indexed: double, cat74_indexed: double, cat75_indexed: double, cat76_indexed: double, cat77_indexed: double, cat78_indexed: double, cat79_indexed: double, cat80_indexed: double, cat81_indexed: double, cat82_indexed: double, cat83_indexed: double, cat84_indexed: double, cat85_indexed: double, cat86_indexed: double, cat87_indexed: double, cat88_indexed: double]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexed = df_indexed[labelCol + featuresCol]\n",
    "#df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+--------------------+\n",
      "| mark|             label|            features|\n",
      "+-----+------------------+--------------------+\n",
      "|train| 2213.179931640625|[0.72630000114440...|\n",
      "|train|1283.5999755859375|[0.33051401376724...|\n",
      "|train| 3005.090087890625|[0.26184099912643...|\n",
      "|train| 939.8499755859375|[0.32159399986267...|\n",
      "|train|  2763.85009765625|[0.27320399880409...|\n",
      "|train|   5142.8701171875|[0.54667001962661...|\n",
      "|train| 1132.219970703125|[0.47144699096679...|\n",
      "|train|           3585.75|[0.82659101486206...|\n",
      "|train|  10280.2001953125|[0.33051401376724...|\n",
      "|train|     6184.58984375|[0.72630000114440...|\n",
      "|train|  6396.85009765625|[0.49606299400329...|\n",
      "|train|  5965.72998046875|[0.52069801092147...|\n",
      "|train| 1193.050048828125|[0.32159399986267...|\n",
      "|train|  1071.77001953125|[0.35135799646377...|\n",
      "|train| 585.1799926757812|[0.89433300495147...|\n",
      "|train| 1395.449951171875|[0.47289198637008...|\n",
      "|train|  6609.31982421875|[0.42416200041770...|\n",
      "|train| 2658.699951171875|[0.83474701642990...|\n",
      "|train|  4167.31982421875|[0.48881599307060...|\n",
      "|train| 3797.889892578125|[0.39195600152015...|\n",
      "+-----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lf = df_indexed.rdd.map(lambda r: (row(r[0], r[1],DenseVector(r[2:])))).toDF()\n",
    "lf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+--------------------+--------+\n",
      "| mark|             label|            features|   index|\n",
      "+-----+------------------+--------------------+--------+\n",
      "|train| 2213.179931640625|[0.72630000114440...| 22259.0|\n",
      "|train|1283.5999755859375|[0.33051401376724...|132074.0|\n",
      "|train| 3005.090087890625|[0.26184099912643...|106882.0|\n",
      "+-----+------------------+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# index label\n",
    "# convert numeric label to categorical, which is required by\n",
    "# decisionTree and randomForest\n",
    "model = StringIndexer(inputCol = 'label', outputCol='index').fit(lf)\n",
    "lf = model.transform(lf)\n",
    " \n",
    "lf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mark: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- index: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = lf.where(lf.mark =='train')\n",
    "test = lf.where(lf.mark =='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random split further to get train/validate\n",
    "#train, validate = train.randomSplit([0.7,0.3], seed =121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model based on auc ROC(default for binary classification)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    " \n",
    "def testModel(model, validate = validate):\n",
    "    pred = model.transform(validate)\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol = 'label')\n",
    "    return evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(numTrees=20, maxDepth=8, maxMemoryInMB=512, seed=142, labelCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.36562422e-02,   5.69502299e-02,   1.58322610e-02,\n",
       "          1.14801508e-02,   4.02885024e-03,   9.06710967e-03,\n",
       "          4.39887957e-02,   5.19509966e-03,   5.08359114e-03,\n",
       "          8.50822868e-03,   2.12329725e-02,   2.35456355e-02,\n",
       "          4.90439090e-03,   7.69191045e-03,   1.42280533e-02,\n",
       "          4.54697969e-03,   3.26044916e-02,   9.07192315e-03,\n",
       "          5.99028670e-02,   2.41502350e-03,   9.79931364e-04,\n",
       "          6.56895658e-07,   5.93005566e-04,   2.61677691e-04,\n",
       "          6.11494424e-05,   4.61614237e-04,   7.83558759e-05,\n",
       "          2.02807333e-05,   1.29534728e-05,   1.82964431e-03,\n",
       "          4.21814831e-04,   1.66551204e-03,   2.46511485e-03,\n",
       "          2.71117498e-03,   6.61502071e-04,   3.02149654e-04,\n",
       "          1.92254325e-04,   7.68516017e-04,   1.91066915e-04,\n",
       "          3.55872148e-04,   1.40022452e-04,   5.11584636e-05,\n",
       "          2.49484467e-03,   2.46245495e-03,   5.96703856e-03,\n",
       "          6.66929953e-04,   1.64598187e-03,   5.42290851e-04,\n",
       "          2.93305855e-04,   5.69362141e-04,   5.24257494e-03,\n",
       "          4.46083099e-04,   1.90389632e-04,   3.72746349e-04,\n",
       "          2.63324780e-05,   1.77893194e-03,   3.93884558e-03,\n",
       "          2.97295779e-04,   2.24062870e-03,   7.99744084e-03,\n",
       "          2.89047908e-04,   6.21075083e-05,   9.15374488e-06,\n",
       "          8.75172092e-02,   2.84545067e-04,   5.78181907e-04,\n",
       "          1.40231555e-04,   1.63809853e-04,   1.80099824e-04,\n",
       "          1.23175847e-04,   7.83428597e-05,   2.94381439e-04,\n",
       "          6.76113334e-04,   1.75329267e-04,   7.92152630e-05,\n",
       "          1.27314177e-05,   2.78875145e-03,   1.92551975e-02,\n",
       "          1.40531220e-03,   4.18994522e-04,   1.51195901e-03,\n",
       "          1.49896478e-03,   6.68956982e-04,   6.31359440e-04,\n",
       "          1.47188719e-01,   2.61081979e-01,   3.68264896e-02,\n",
       "          1.99551440e-03,   1.05544685e-03,   1.92550503e-03,\n",
       "          8.36127116e-04,   6.79512682e-03,   1.79173668e-02,\n",
       "          2.00839924e-04]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "        86, 87, 88, 89, 90, 91, 92, 93, 94], dtype=int32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances.values,model.featureImportances.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(mark='train', label=36.0, features=DenseVector([0.5851, 0.4222, 0.5714, 0.5547, 0.5942, 0.4992, 0.4438, 0.4352, 0.662, 0.5772, 0.644, 0.6309, 0.3543, 0.4073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 17.0, 24.0, 0.0, 2.0, 0.0]), index=97543.0, prediction=2448.4054668797735)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.transform(validate).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(mark='test', label=0.0, features=DenseVector([0.3216, 0.2991, 0.2469, 0.4029, 0.2811, 0.4666, 0.3177, 0.6123, 0.3437, 0.3802, 0.3777, 0.3699, 0.7041, 0.3926, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]), index=0.0, prediction=1904.7742873124164)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test = model.transform(test)\n",
    "prediction_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test.createOrReplaceTempView('pred_test')\n",
    "testDF.createOrReplaceTempView(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_col = spark.sql(\n",
    "    \"SELECT prediction from pred_test\")\n",
    "id_col = spark.sql(\n",
    "    \"SELECT id from test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id = id_col.toPandas().values.T.tolist()\n",
    "prediction = prediction_col.toPandas().values.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"id\" : id[0], \"loss\" : prediction[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"submission_s2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(labelCol = 'label', maxDepth=8, maxBins=15,stepSize=0.8, maxIter=5,  maxMemoryInMB=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2155.8509524294614"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(test).head().prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test.createOrReplaceTempView('pred_test')\n",
    "testDF.createOrReplaceTempView(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_col = spark.sql(\n",
    "    \"SELECT prediction from pred_test\")\n",
    "id_col = spark.sql(\n",
    "    \"SELECT id from test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id = id_col.toPandas().values.T.tolist()\n",
    "prediction = prediction_col.toPandas().values.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"id\" : id[0], \"loss\" : prediction[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"submission_s3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(prediction_test)\n",
    "print(\"Test Error = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test.createOrReplaceTempView('pred_test')\n",
    "testDF.createOrReplaceTempView(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_col = spark.sql(\n",
    "    \"SELECT prediction from pred_test\")\n",
    "id_col = spark.sql(\n",
    "    \"SELECT id from test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id = id_col.toPandas().values.T.tolist()\n",
    "prediction = prediction_col.toPandas().values.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"id\" : id[0], \"loss\" : prediction[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"submission_gbt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
